{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# from skimage import io, transform\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import unicodedata # ??\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import csv\n",
    "import json\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "# define directory structure needed for data processing\n",
    "RAW_DATA_DIR = os.path.join('..', 'data/', 'raw_data/')\n",
    "FORMAL_DATA_DIR = os.path.join('..', 'data/', 'formal_data/')\n",
    "UNKNOWN_TOKEN = \"unk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.strip()).replace(\"\\t\", \" \")\n",
    "    return s\n",
    "\n",
    "\n",
    "# precondition: two fields with name: \"headline\" and \"text\"\n",
    "def splitData(fname, test_size=0.2, val_size=0.2): \n",
    "    df = pd.read_csv('../data/' + fname, encoding='latin-1')\n",
    "    df = df[[\"headlines\", \"text\"]] # summary text, not the entire article\n",
    "    df[\"headlines\"] = df[\"headlines\"].apply(normalizeString)\n",
    "    df[\"text\"] = df[\"text\"].apply(normalizeString)\n",
    "\n",
    "    df = df.sample(frac=1).reset_index(drop=True) # shuffle data\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=test_size, random_state=1)\n",
    "    df_train, df_val = train_test_split(df_train, test_size=val_size, random_state=1)\n",
    "    df_train.to_csv(RAW_DATA_DIR + \"train.csv\", index=False, sep=\"\\t\",header=False)\n",
    "    df_val.to_csv(RAW_DATA_DIR + \"val.csv\", index=False, sep=\"\\t\", header=False)\n",
    "    df_test.to_csv(RAW_DATA_DIR + \"test.csv\", index=False, sep=\"\\t\", header=False)\n",
    "    \n",
    "# # TODO: check whether \"text\" is in fact the summary and corresponds to the headline\n",
    "\n",
    "splitData(\"news_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
