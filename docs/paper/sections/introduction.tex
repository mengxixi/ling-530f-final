\section{Introduction}

\begin{enumerate}
\item At the end of intro, state that we did the reduced task which is only generating a headline (as a summary) on a news article.
\end{enumerate}


Abstractive text summarization is the task of generating a concise summary that retains the key ideas from a document with high coherence. As the amount of textual data in the world grows in an ever-increasing rate, the ability to quickly index and search from these documents becomes crucial. To provide a comprehensive summary that captures all the relevant pieces usually requires human experts to perform the task, which is prohibitively costly as the amount of work scales. This motivates the use of modern technology to train computers to succeed at such tasks. Machine-generated summaries are also less prone to human-bias (either intended or not) given a relatively neutral database to learn from. In this work, we explore the closely related task of news headline generation as a reduced form of abstractive text summarization. We employ deep learning architectures such as sequence-to-sequence models with attention as the foundation framework, and we perform experiments with different language models for a thorough comparison.