\section{Motivation}
Automatic text summarization is an important task in Natural Language Processing (NLP). With the ever-growing amount of textual material emerging, the ability to efficiently and accurately generate summaries becomes crucial \cite{gambhir2017recent}. Summaries can allow us to quickly index documents and make selections in a much shorter period of time. It is also less prone to personal bias when performed by a machine. Therefore, in this project, we will explore deep learning methods to hopefully provide a general approach to this problem.

\section{Problem Statement}
We will implement a Recurrent Neural Network based model which given a short article (e.g., short news stories), it will generate a summary (around 1 to 3 sentences) that is fluent and concise. The process is essentially a sequence-to-sequence learning problem. If time and computational resource allows, we will extend the problem to a larger setting, for example, generating abstracts from academic publications. 


\section{Methods}
We will be experimenting with recent advancements in sequence-to-sequence models, which are encoder-decoder recurrent neural networks (RNNs). We will feed in the input article as a sequence of word embeddings from pre-trained language models such as \texttt{GloVe}, \texttt{fastText} or \texttt{Word2Vec} \cite{pennington2014glove, bojanowski2017enriching, mikolov2013efficient}. We will also explore options that may enhance our performance, such as attention mechanism, rich sentence features \cite{nallapati2016abstractive}, convolution neural networks (CNNs) and other architecture based on further research. \todo{How does your project compare to NLP and deep learning published research?} 

To ensure a productive progress of our project, we will take the following steps as a breakdown of the larger task. First, we will start with a small dataset of news articles, and we will treat the title as the target summary that we try to generate. This way, we can ensure our overall seq2seq framework is working and able to generate somewhat sensible one-line summaries. Then we will add in enhancement techniques to further improve our model on the ROUGE metric system \cite{lin2004rouge}. Finally, we will scale up the problem by using a more comprehensive dataset in which the summaries are a bit more informative. 

\section{Dataset}

We will be using the DeepMind Q\&A Dataset (DMQA) which was created from news article for Q\&A research. It consists of two parts: CNN news and Daily Mail (90k and 197k documents respectively). We will use the headlines and the article body for sequence-to-sequence learning.


\section{Evaluation}
For quantitative evaluation, we will use the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) metrics that are often used for evaluating automatic summarization and machine translation systems. Specifically, we wil use the ROUGE-1 (overlap of 1-gram), ROUGE-2 (overlap of bigrams) and ROUGE-L (longest common subsequence) measures to compare our model against the baseline model. To avoid reinventing the wheel, we will use the pyrouge\footnote{https://pypi.org/project/pyrouge}. Python package for ROUGE evaluation scripts and configuration files. 
We use the RNN encoder-decoder model introduced in \cite{cho2014learning} as our baseline model because it is the most feasible to implement and to evaluate in our dataset. Furthermore, we will evaluate our model qualitatively by randomly selecting a few summaries generated by our model and manually compare them with the corresponding human written summaries. We will then examine the fluency, accuracy and comprehensiveness of the machine-generated results.

\section{Tasks and Assignment}

The project can be brokendown as the following tasks:

\noindent
\textbf{Dataset}
\begin{compactitem}
\item Data cleaning (Fan)
\item Summary statistics for the dataset
\end{compactitem}

\noindent
\textbf{Model}
\begin{compactitem}
\item Baseline neural network (Fan).
\item Format dataset in input form 
\item Develop model against the baseline (Fan, Meny, Yin).
\item Word embedding on input sentences.
\end{compactitem}

\noindent
\textbf{Evaluation}
\begin{compactitem}
\item \texttt{pyrouge} setup for evaluation.
\item Evaluate model quantitatively.
\item Evaluate model qualitatively.
\end{compactitem}

\noindent
\textbf{Related work reading}
\begin{compactitem}
\item RNN neural network
\item Text summarization in general (Fan)
\item Abstractive text summarization (Fan)
\item Word embedding
\end{compactitem}

\noindent
\textbf{Report Writing}
\begin{compactitem}
\item Experimental result generation and formatting
\item Abstract
\item Introduction
\item Related work (Fan)
\item Methodology (Fan)
\item Experiment
\item Result
\item Conclusion
\end{compactitem}


\section{Timeline}

\noindent
\textbf{Week 1 (from Nov 5): Basic ML framework}
\begin{compactitem}
\item Data cleaning 
\item Baseline neural network 
\item Word embedding on input sentences.
\item Format dataset in input form 
\item \texttt{pyrouge} setup for evaluation.
\end{compactitem}

\noindent
\textbf{Week 2: Model development}
\begin{compactitem}
\item Summary statistics for the dataset
\item Develop model against the baseline
\end{compactitem}

\noindent
\textbf{Week 3: Evaluation and reading}
\begin{compactitem}
\item Evaluate model quantitatively.
\item Evaluate model qualitatively.
\item Related work reading.
\end{compactitem}

\noindent
\textbf{Week 4 (till the end): Writing}
\begin{compactitem}
\item Report writing
\end{compactitem}

%\newpage
\bibliography{acl2018}
\bibliographystyle{acl_natbib}
